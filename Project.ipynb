{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import timm\n",
    "import numpy as np\n",
    "import torcheval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier ./train.txt a été supprimé avec succès.\n",
      "Le fichier ./val.txt a été supprimé avec succès.\n",
      "Le fichier ./test.txt a été supprimé avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Chemin vers le dossier principal contenant les données\n",
    "data_folder_train = './project_data/train'\n",
    "data_folder_validation = './project_data/val'\n",
    "# Chemin vers le fichier texte de sortie\n",
    "train_file = './train.txt'\n",
    "val_file = \"./val.txt\"\n",
    "test_file = \"./test.txt\"\n",
    "\n",
    "def file_exist(path) :\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "        print(f\"Le fichier {path} a été supprimé avec succès.\")\n",
    "    else:\n",
    "        print(f\"Le fichier {path} n'existe pas.\")\n",
    "\n",
    "def get_labels_from_path(image_path, base_folder):\n",
    "    # Obtenez le chemin relatif par rapport au dossier principal\n",
    "    relative_path = os.path.relpath(image_path, start=base_folder)\n",
    "    # Séparez le chemin relatif en éléments\n",
    "    path_elements = os.path.dirname(relative_path).split(os.path.sep)\n",
    "    label = path_elements[0]\n",
    "    if label == \"FakeManipulation-1\" or label == \"FakeManipulation-2\" :\n",
    "        return \"1\"\n",
    "    elif label == \"FakeManipulation-3\" or label == \"FakeManipulation-4\" :\n",
    "        return \"12\"\n",
    "    elif label == \"FakeManipulation-5\" :\n",
    "        return \"13\"\n",
    "    elif label == \"Real-1\" or label == \"Real-2\" or label == \"Real-3\" or label == \"Real-4\" :\n",
    "        return \"0\"\n",
    "    else :\n",
    "        print(\"error\")\n",
    "\n",
    "\n",
    "\n",
    "# Ouvrir le fichier en mode écriture\n",
    "def create_txt(data_folder, train) :\n",
    "    if (train) :\n",
    "        output_txt_file = train_file\n",
    "        txt_file = open(output_txt_file, 'a')\n",
    "        # Parcourir les dossiers et sous-dossiers\n",
    "        for root, dirs, files in os.walk(data_folder):\n",
    "            for file in files:\n",
    "                # Vérifier si le fichier est une image (vous pouvez ajuster les extensions selon votre cas)\n",
    "                if file.endswith('.jpg') :\n",
    "                    # Chemin complet du fichier\n",
    "                    image_path = os.path.join(root, file)\n",
    "\n",
    "                    # Obtenir les labels à partir du chemin du fichier ou de toute autre méthode appropriée\n",
    "                    labels = get_labels_from_path(image_path, data_folder)\n",
    "\n",
    "                    # Écrire dans le fichier texte\n",
    "                    txt_file.write(f'{image_path} {\" \".join(map(str, labels))}\\n')\n",
    "                else :\n",
    "                    print(\"Error\")\n",
    "    else :\n",
    "        indice = 0\n",
    "        output_txt_file_val = val_file\n",
    "        output_txt_file_test = test_file\n",
    "        txt_file_val = open(output_txt_file_val, 'a')\n",
    "        txt_file_test = open(output_txt_file_test, 'a')\n",
    "\n",
    "        for root, dirs, files in os.walk(data_folder):\n",
    "            for file in files:\n",
    "                indice += 1\n",
    "                # Vérifier si le fichier est une image (vous pouvez ajuster les extensions selon votre cas)\n",
    "                if file.endswith('.jpg') :\n",
    "                    # Chemin complet du fichier\n",
    "                    image_path = os.path.join(root, file)\n",
    "\n",
    "                    # Obtenir les labels à partir du chemin du fichier ou de toute autre méthode appropriée\n",
    "                    labels = get_labels_from_path(image_path, data_folder)\n",
    "                    # Écrire dans le fichier texte\n",
    "                    if indice % 2 == 0 :\n",
    "                        txt_file_val.write(f'{image_path} {labels}\\n')     \n",
    "                    else :               \n",
    "                        txt_file_test.write(f'{image_path} {labels}\\n')     \n",
    "                else :\n",
    "                    print(\"Error\")\n",
    "\n",
    "\n",
    "file_exist(train_file)\n",
    "file_exist(val_file)\n",
    "file_exist(test_file)\n",
    "\n",
    "create_txt(data_folder_train, 1)\n",
    "create_txt(data_folder_validation, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Définir les transformations\n",
    "transform_augmented = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Honggu Liu\n",
    "\"\"\"\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt_path, transform=None, target_transform=None):\n",
    "        fh = open(txt_path, 'r')\n",
    "        imgs = []\n",
    "        for line in fh:\n",
    "            line = line.rstrip()\n",
    "            words = line.split()\n",
    "            imgs.append((words[0], int(words[1])))\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.class_to_idx = {'0': 0, '1': 1, '12': 2, '13': 3}\n",
    "        self.classes = ['Real', 'FakeManipulation-1', 'FakeManipulation-2', 'FakeManipulation-3']\n",
    "        \n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        img = Image.open(fn).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Créer des ensembles de données\n",
    "train_data = MyDataset(txt_path=train_file, transform=transform_augmented)\n",
    "val_data = MyDataset(txt_path=val_file, transform=transform)\n",
    "test_data = MyDataset(txt_path=test_file, transform=transform)\n",
    "\n",
    "# Créer des chargeurs de données\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_correct(pred, label):\n",
    "    if label == 0 and pred == 0:\n",
    "        return True\n",
    "    elif (label == 0 and pred != 0) :                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "        return False\n",
    "    elif (label != 0 and pred == 0) :\n",
    "        return False\n",
    "    else :\n",
    "        return True\n",
    "\n",
    "\n",
    "# Charger EfficientNet B3\n",
    "model = timm.create_model('efficientnet_b3', pretrained=True)\n",
    "\n",
    "\n",
    "# Modifier la couche de sortie pour correspondre au nombre de classes de votre tâche\n",
    "num_classes = len(train_data.classes)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "\n",
    "# Définir le périphérique\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Définir le critère de perte et l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "# Entraînement du modèle (à adapter en fonction de vos besoins)\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward et optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Enregistrer le modèle\n",
    "torch.save(model.state_dict(), 'model.ckpt')\n",
    "\n",
    "# Charger le modèle\n",
    "model.load_state_dict(torch.load('model.ckpt'))\n",
    "model.eval()\n",
    "\n",
    "# Test le model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    missed = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        if is_correct(predicted, labels) :\n",
    "            correct += 1\n",
    "        else :\n",
    "            missed += 1\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy of the model on the test images: {correct / total}%')\n",
    "print(f'Recall of the model on the test images: {correct / (correct + missed)}%')\n",
    "print(f'Precision of the model on the test images: {correct / (correct + (total - correct))}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from network.models import model_selection\n",
    "from network.mesonet import Meso4, MesoInception4\n",
    "from dataset.transform import xception_default_data_transforms\n",
    "from dataset.mydataset import MyDataset\n",
    "def main():\n",
    "\targs = parse.parse_args()\n",
    "\tname = args.name\n",
    "\tcontinue_train = args.continue_train\n",
    "\ttrain_list = args.train_list\n",
    "\tval_list = args.val_list\n",
    "\tepoches = args.epoches\n",
    "\tbatch_size = args.batch_size\n",
    "\tmodel_name = args.model_name\n",
    "\tmodel_path = args.model_path\n",
    "\toutput_path = os.path.join('./output', name)\n",
    "\tif not os.path.exists(output_path):\n",
    "\t\tos.mkdir(output_path)\n",
    "\ttorch.backends.cudnn.benchmark=True\n",
    "\ttrain_dataset = MyDataset(txt_path=train_list, transform=xception_default_data_transforms['train'])\n",
    "\tval_dataset = MyDataset(txt_path=val_list, transform=xception_default_data_transforms['val'])\n",
    "\ttrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=8)\n",
    "\tval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=8)\n",
    "\ttrain_dataset_size = len(train_dataset)\n",
    "\tval_dataset_size = len(val_dataset)\n",
    "\tmodel = model_selection(modelname='xception', num_out_classes=2, dropout=0.5)\n",
    "\tif continue_train:\n",
    "\t\tmodel.load_state_dict(torch.load(model_path))\n",
    "\tmodel = model.cuda()\n",
    "\tcriterion = nn.CrossEntropyLoss()\n",
    "\toptimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "\tscheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\tmodel = nn.DataParallel(model)\n",
    "\tbest_model_wts = model.state_dict()\n",
    "\tbest_acc = 0.0\n",
    "\titeration = 0\n",
    "\tfor epoch in range(epoches):\n",
    "\t\tprint('Epoch {}/{}'.format(epoch+1, epoches))\n",
    "\t\tprint('-'*10)\n",
    "\t\tmodel.train()\n",
    "\t\ttrain_loss = 0.0\n",
    "\t\ttrain_corrects = 0.0\n",
    "\t\tval_loss = 0.0\n",
    "\t\tval_corrects = 0.0\n",
    "\t\tfor (image, labels) in train_loader:\n",
    "\t\t\titer_loss = 0.0\n",
    "\t\t\titer_corrects = 0.0\n",
    "\t\t\timage = image.cuda()\n",
    "\t\t\tlabels = labels.cuda()\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = model(image)\n",
    "\t\t\t_, preds = torch.max(outputs.data, 1)\n",
    "\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\titer_loss = loss.data.item()\n",
    "\t\t\ttrain_loss += iter_loss\n",
    "\t\t\titer_corrects = torch.sum(preds == labels.data).to(torch.float32)\n",
    "\t\t\ttrain_corrects += iter_corrects\n",
    "\t\t\titeration += 1\n",
    "\t\t\tif not (iteration % 20):\n",
    "\t\t\t\tprint('iteration {} train loss: {:.4f} Acc: {:.4f}'.format(iteration, iter_loss / batch_size, iter_corrects / batch_size))\n",
    "\t\tepoch_loss = train_loss / train_dataset_size\n",
    "\t\tepoch_acc = train_corrects / train_dataset_size\n",
    "\t\tprint('epoch train loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "\t\tmodel.eval()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor (image, labels) in val_loader:\n",
    "\t\t\t\timage = image.cuda()\n",
    "\t\t\t\tlabels = labels.cuda()\n",
    "\t\t\t\toutputs = model(image)\n",
    "\t\t\t\t_, preds = torch.max(outputs.data, 1)\n",
    "\t\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\t\tval_loss += loss.data.item()\n",
    "\t\t\t\tval_corrects += torch.sum(preds == labels.data).to(torch.float32)\n",
    "\t\t\tepoch_loss = val_loss / val_dataset_size\n",
    "\t\t\tepoch_acc = val_corrects / val_dataset_size\n",
    "\t\t\tprint('epoch val loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\t\t\tif epoch_acc > best_acc:\n",
    "\t\t\t\tbest_acc = epoch_acc\n",
    "\t\t\t\tbest_model_wts = model.state_dict()\n",
    "\t\tscheduler.step()\n",
    "\t\t#if not (epoch % 40):\n",
    "\t\ttorch.save(model.module.state_dict(), os.path.join(output_path, str(epoch) + '_' + model_name))\n",
    "\tprint('Best val Acc: {:.4f}'.format(best_acc))\n",
    "\tmodel.load_state_dict(best_model_wts)\n",
    "\ttorch.save(model.module.state_dict(), os.path.join(output_path, \"best.pkl\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tparse = argparse.ArgumentParser(\n",
    "\t\tformatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\tparse.add_argument('--name', '-n', type=str, default='fs_xception_c0_299')\n",
    "\tparse.add_argument('--train_list', '-tl' , type=str, default = './data_list/FaceSwap_c0_train.txt')\n",
    "\tparse.add_argument('--val_list', '-vl' , type=str, default = './data_list/FaceSwap_c0_val.txt')\n",
    "\tparse.add_argument('--batch_size', '-bz', type=int, default=64)\n",
    "\tparse.add_argument('--epoches', '-e', type=int, default='20')\n",
    "\tparse.add_argument('--model_name', '-mn', type=str, default='fs_c0_299.pkl')\n",
    "\tparse.add_argument('--continue_train', type=bool, default=False)\n",
    "\tparse.add_argument('--model_path', '-mp', type=str, default='./output/df_xception_c0_299/1_df_c0_299.pkl')\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "from network.models import model_selection\n",
    "from dataset.transform import xception_default_data_transforms\n",
    "from dataset.mydataset import MyDataset\n",
    "def main():\n",
    "\targs = parse.parse_args()\n",
    "\ttest_list = args.test_list\n",
    "\tbatch_size = args.batch_size\n",
    "\tmodel_path = args.model_path\n",
    "\ttorch.backends.cudnn.benchmark=True\n",
    "\ttest_dataset = MyDataset(txt_path=test_list, transform=xception_default_data_transforms['test'])\n",
    "\ttest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=8)\n",
    "\ttest_dataset_size = len(test_dataset)\n",
    "\tcorrects = 0\n",
    "\tacc = 0\n",
    "\t#model = torchvision.models.densenet121(num_classes=2)\n",
    "\tmodel = model_selection(modelname='xception', num_out_classes=2, dropout=0.5)\n",
    "\tmodel.load_state_dict(torch.load(model_path))\n",
    "\tif isinstance(model, torch.nn.DataParallel):\n",
    "\t\tmodel = model.module\n",
    "\tmodel = model.cuda()\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tfor (image, labels) in test_loader:\n",
    "\t\t\timage = image.cuda()\n",
    "\t\t\tlabels = labels.cuda()\n",
    "\t\t\toutputs = model(image)\n",
    "\t\t\t_, preds = torch.max(outputs.data, 1)\n",
    "\t\t\tcorrects += torch.sum(preds == labels.data).to(torch.float32)\n",
    "\t\t\tprint('Iteration Acc {:.4f}'.format(torch.sum(preds == labels.data).to(torch.float32)/batch_size))\n",
    "\t\tacc = corrects / test_dataset_size\n",
    "\t\tprint('Test Acc: {:.4f}'.format(acc))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tparse = argparse.ArgumentParser(\n",
    "\t\tformatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\tparse.add_argument('--batch_size', '-bz', type=int, default=32)\n",
    "\tparse.add_argument('--test_list', '-tl', type=str, default='./data_list/Deepfakes_c0_test.txt')\n",
    "\tparse.add_argument('--model_path', '-mp', type=str, default='./pretrained_model/df_c0_best.pkl')\n",
    "\tmain()\n",
    "\tprint('Hello world!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_path):\n",
    "    Accuracy, Recall, Precision, AUC = 0, 0, 0\n",
    "    \"\"\"\n",
    "    You need to finish this function.\n",
    "    \"\"\"\n",
    "    return Accuracy, Recall, Precision, AUC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
